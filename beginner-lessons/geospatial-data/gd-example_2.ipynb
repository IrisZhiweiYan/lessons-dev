{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geospatial data - Try it notebook #2\n",
    "## Making thematic maps using indirect georeferencing\n",
    "Here we're going to make a map of new COVID case rates for a particular date for all the states in the continental US.\n",
    "\n",
    "As usual, we start by importing...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "init_cell": true,
    "tags": [
     "Hide"
    ]
   },
   "outputs": [],
   "source": [
    "# This code cell starts the necessary setup for Hour of CI lesson notebooks.\n",
    "# First, it enables users to hide and unhide code by producing a 'Toggle raw code' button below.\n",
    "# Second, it imports the hourofci package, which is necessary for lessons and interactive Jupyter Widgets.\n",
    "# Third, it helps hide/control other aspects of Jupyter Notebooks to improve the user experience\n",
    "# This is an initialization cell\n",
    "# It is not displayed because the Slide Type is 'Skip'\n",
    "\n",
    "from IPython.display import HTML, IFrame, Javascript, display\n",
    "from ipywidgets import interactive\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import Layout\n",
    "\n",
    "import getpass # This library allows us to get the username (User agent string)\n",
    "\n",
    "# import package for hourofci project\n",
    "import sys\n",
    "sys.path.append('../../supplementary') # relative path (may change depending on the location of the lesson notebook)\n",
    "import hourofci\n",
    "\n",
    "# load javascript to initialize/hide cells, get user agent string, and hide output indicator\n",
    "# hide code by introducing a toggle button \"Toggle raw code\"\n",
    "HTML(''' \n",
    "    <script type=\"text/javascript\" src=\\\"../../supplementary/js/custom.js\\\"></script>\n",
    "    \n",
    "    <style>\n",
    "        .output_prompt{opacity:0;}\n",
    "    </style>\n",
    "    \n",
    "    <input id=\"toggle_code\" type=\"button\" value=\"Toggle raw code\">\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas\n",
    "import json\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll download the state boundary geometry from the Census Bureau and read it into a geopandas geodataframe called 'states'. In the code chunk below we also:\n",
    "\n",
    "- Print the dimension of the table (rows = 50 states plus DC and Puerto Rico)\n",
    "- Display the first 5 rows of the file. Note the geography column at the right. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "states = geopandas.read_file(\"http://www2.census.gov/geo/tiger/GENZ2014/shp/cb_2014_us_state_20m.zip\")\n",
    "print(\"The dimension (rows, columns) of the states geodataframe is \", states.shape)\n",
    "states.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "states = geopandas.read_file(\"http://www2.census.gov/geo/tiger/GENZ2014/shp/cb_2014_us_state_20m.zip\", index_col = \"NAME\")\n",
    "print(\"The dimension (rows, columns) of the states geodataframe is \", states.shape)\n",
    "states.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll make a quick plot to check our data are OK. \n",
    "\n",
    "In Python, there are many ways to make maps. In Try-it notebook #1, we used the ipyleaflet package to make an interactive map. \n",
    "\n",
    "This time we'll use a simple plot module in the matplotlib package that comes in the basic install. There is no need to import this package. It plots long lat pairs as simple cartesian coordinates in a rectangular frame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "states.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm, that's not very pretty. Let's constrain this map to only the continental US. \n",
    "\n",
    "There are many ways to do this. Here we'll just mask out the continental area by clipping any rows that fall outside a rectangle defined by the appropriate lat/long limits of the continental US. We'll use a geometry tool (Polygon) from the package shapely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Polygon\n",
    "mask = Polygon([(-140, 20), (-140, 48), (-60, 48), (-60, 20), (-140, 20)])\n",
    "states = geopandas.clip(states, mask)\n",
    "print(\"The dimension (rows, columns) of the states geodataframe is \",states.shape)\n",
    "states.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still not a great map, but at least we can see the shape of the country.\n",
    "\n",
    "Now we'll get the COVID data. We can get it right from the main source everyone is accessing, Johns Hopkins University. Here is their highly-cited <a href = 'https://www.arcgis.com/apps/opsdashboard/index.html#/bda7594740fd40299423467b48e9ecf6'> dashboard.</a>\n",
    "\n",
    "In their daily updated data repository on GitHub, there are data for each state for every day since April 12 2020. To make a quick map here, we'll just get one day's data, say October 2, 2020. \n",
    "\n",
    "Descriptions of the data fields (columns) can be found <a href='https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data/'>here.</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cases = pandas.read_csv('https://github.com/CSSEGISandData/COVID-19/raw/master/csse_covid_19_data/csse_covid_19_daily_reports_us/10-02-2020.csv')\n",
    "cases.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice there are several geographic references in these data, including a lat/long pair for each state. This is a point which isn't a great way to represent a state's extent. So we need to join this to the boundary geometry we downloaded earlier. \n",
    "\n",
    "We'll join these two files using the name of the state as the key. First we have to determine what label is used on each column that contains the state names.\n",
    "\n",
    "- Look back at the states table. What is the name of the column that contains the state names? (be sure to note the exact capitalization you see there). \n",
    "    \n",
    "- Look at the cases table. What is the label of the column that contains the state names? \n",
    "\n",
    "Since these column labels need to be the same, we'll change the label in the cases table to match the states table with the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cases = cases.rename(columns={'Province_State': 'NAME'})\n",
    "cases.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll merge these two files together using NAME as the common key. This will add the data for each state in the cases table to the row containing the data for the same state in the states table. After you execute the following command, scroll the table to the right and you'll see what happened."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = states.merge(cases, on='NAME')\n",
    "states.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excellent! Now we've got a single table that contains both the geometry and the data we want to map. Let's take a look at it on a map!\n",
    "\n",
    "The next line of code will plot the state areas again, but this time colored according to the values in a particular column. We'll use Incident Rate (daily reported cases per 100,000)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "states.plot(column='Incident_Rate', cmap='OrRd', scheme='quantiles', legend=True, figsize=(10, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, it's not a publication quality map, but it does show our data. The legend shows the quintile range values. Thus the 20% of the states with the lowest rates are in the pale yellow color, with values between 283 and 1324 cases per 100,000 population. The states in top 20% are shown in the dark brown color and their rates range from 2864 to 3601 per 100,000 population."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "7A"
    ]
   },
   "source": [
    "OK, nice maps! Let's now go back into the slides and dive deeper into geospatial data and learn about the many ways information about the world can be stored in a computer.\n",
    "\n",
    "<a href=\"gd-6.ipynb\" class=\"link-logging\">Click here to go on to the next section.</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---- end ----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternative approach with ipyleaflet\n",
    "\n",
    "I wanted to do this with ipyleaflet, but couldn't get the code to work. Perhaps it's way too complex anyway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipyleaflet import Map, GeoData\n",
    "states_layer = GeoData(geo_dataframe = states)\n",
    "mymap1 = Map(center=(40,-100), zoom = 4)\n",
    "mymap1.add_layer(states_layer)\n",
    "mymap1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states.to_file('states_json', driver='GeoJSON')\n",
    "with open('states_json') as json_file:\n",
    "    states_dict=json.load(json_file)\n",
    "states_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following code didn't work. Something to do with ipyleaflet needing join data to be in a dictionary but I couldn't figure out how to get the key in the first position of the unemployment dict... Note, there are some example code chunks below that don't follow the flow. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import ipyleaflet\n",
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "import requests\n",
    "from ipywidgets import link, FloatSlider\n",
    "from branca.colormap import linear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def load_data(url, filename, file_type):\n",
    "    r = requests.get(url)\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(r.content.decode(\"utf-8\"))\n",
    "    with open(filename, 'r') as f:\n",
    "        return file_type(f)\n",
    "\n",
    "geo_json_data = load_data(\n",
    "    'https://raw.githubusercontent.com/jupyter-widgets/ipyleaflet/master/examples/us-states.json',\n",
    "    'us-states.json',\n",
    "     json.load)\n",
    "\n",
    "unemployment = load_data(\n",
    "    'https://raw.githubusercontent.com/jupyter-widgets/ipyleaflet/master/examples/US_Unemployment_Oct2012.csv',\n",
    "    'US_Unemployment_Oct2012.csv',\n",
    "     pd.read_csv)\n",
    "\n",
    "unemployment =  dict(zip(unemployment['State'].tolist(), unemployment['Unemployment'].tolist()))\n",
    "\n",
    "layer = ipyleaflet.Choropleth(\n",
    "    geo_data=geo_json_data,\n",
    "    choro_data=unemployment,\n",
    "    colormap=linear.YlOrRd_04,\n",
    "    border_color='black',\n",
    "    style={'fillOpacity': 0.8, 'dashArray': '5, 5'})\n",
    "\n",
    "m = ipyleaflet.Map(center = (43,-100), zoom = 4)\n",
    "m.add_layer(layer)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Incident_Rate =  dict(zip(cases['NAME'].tolist(), cases['Incident_Rate'].tolist()))\n",
    "Incident_Rate                                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(states_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipyleaflet\n",
    "layer = ipyleaflet.Choropleth(\n",
    "    geo_data=states_dict,\n",
    "    choro_data=Incident_Rate\n",
    ")\n",
    "\n",
    "m = ipyleaflet.Map(center = (43,-100), zoom = 4)\n",
    "m.add_layer(layer)\n",
    "m                                                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipyleaflet\n",
    "from branca.colormap import linear\n",
    "layer = ipyleaflet.Choropleth(\n",
    "    geo_data=states_dict,\n",
    "    choro_data=Incident_Rate,\n",
    "    colormap=linear.YlOrRd_04,\n",
    "    border_color='black',\n",
    "    style={'fillOpacity': 0.8, 'dashArray': '5, 5'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = ipyleaflet.Map(center = (43,-100), zoom = 4)\n",
    "m.add_layer(layer)\n",
    "m                                                      "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Initialization Cell",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
